#!/usr/bin/python

# Third party libraries
import sys
from rich import print as rprint
from rich.traceback import install

# Internal library
from lib.ai import command_handler
from lib.ai.arguments import argument_parser
from lib.ai import terminal
from lib.ai.session import interactive_session, passive_session, finish_reason_check
from lib.ai.user_input import initial_message
from lib.ai.user_input import choose_saved_chat
from lib.ai import io
from lib.ai import messages
from lib import config
from lib.desktop.clipboard import send_to_clipboard
from lib.openai import models

# This install function from 'rich' adds syntax highlighting to exceptions
install()

terminal.print_line(to_stderr=True)
terminal.print_title(to_stderr=True)

models.assert_openai_api_key()
text_model_name = config.get_text_model_name()
flags, parameters, prompt_list, query = argument_parser()

if flags['debug']:
    rprint(f'flags: {flags}')
    rprint(f'parameters: {parameters}')
    rprint(f'prompt: {prompt_list}')
    rprint(f'query: {query}')

if flags['edit']:
    command_handler.edit_prompts()
if flags['load']:
    pass
    # loaded_chat = command_handler.load(commands['load'])
    # rprint(loaded_chat)
    # sys.exit(0)

model_list = [m['name'] for m in models.filter_models('gpt')]
if not text_model_name in model_list or flags['model']:
    text_model_name = models.choose_model(flags['model'])
    config.set_text_model_name(text_model_name)

prompt_name, prompt = command_handler.get_prompt(prompt_list)
if not prompt:
    rprint('[yellow]Unknown Prompt[/]')
    rprint('Use "ai -p" to list the prepared prompts')
    rprint('Alternatively, use a period "." to not use a prepared prompt')
    rprint('Example: ai . "What is a Koala?"')
    rprint()
    sys.exit(1)

if not prompt == '.':
    messages.add_user_content(prompt)
    messages.add_assistant_content('Understood, how can I help?')

file_content = command_handler.file_content(flags['file'])
if file_content:
    rprint(f'[yellow]File content loaded: {flags["file"]}[/]')
    messages.add_user_content(file_content)
    if not prompt:
        # If a prepared prompt has not been added, stop the message
        # from the API and ask the user for an initial message
        messages.add_assistant_content('How can I assist you?')

if not query and not flags['interactive'] and not messages.ready_to_send():
    while not query:
        query = initial_message()

if query:
    messages.add_user_content(query)

terminal.print_messages()

if flags['interactive']:
    if flags['verbose']:
        terminal.print_verbose(flags, parameters, prompt_name, None)
    interactive_session(flags, parameters)

if flags['debug']:
    rprint(f'messages: {messages.chat}')


session_data = passive_session(flags, parameters)

finish_reason_check(session_data['finish_reason'])

if flags['verbose']:
    terminal.print_title(top_line=False)
    terminal.print_verbose(
        flags, parameters, prompt_name, session_data['tokens'])

send_to_clipboard(session_data['content'])
if flags['synchronous'] or flags['verbose']:
    print(session_data['content'])
