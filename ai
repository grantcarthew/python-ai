#!/usr/bin/python

# Third party libraries
import sys
from lib.ai.user_input import choose_saved_chat
from lib.ai import io
from rich import print as rprint
from rich.traceback import install

# Internal library
from lib.ai import command_handler
from lib.ai.arguments import argument_parser
from lib.ai import terminal
from lib.ai.session import interactive_session, passive_session, finish_reason_check
from lib.ai.user_input import initial_message
from lib.config import save_config, load_config
from lib.desktop.clipboard import send_to_clipboard
from lib.openai import models

# This install function from 'rich' adds syntax highlighting to exceptions
install()


models.assert_openai_api_key()
config = load_config()
messages = list()
flags, commands, parameters = argument_parser()

if flags['debug']:
    rprint(f'flags: {flags}')
    rprint(f'commands: {commands}')
    rprint(f'parameters: {parameters}')

if commands['help']:
    terminal.print_title(config['model'])
    command_handler.help(interactive=flags['interactive'])
    terminal.print_line()
    sys.exit(0)
if commands['list']:
    command_handler.list(commands['list'])
if commands['edit']:
    command_handler.edit(commands['edit'])
if commands['load']:
    loaded_chat = command_handler.load(commands['load'])
    rprint(loaded_chat)
    sys.exit(0)


model_list = [m['name'] for m in models.filter_models('gpt')]
if not config.get('model') or not config['model'] in model_list or flags['model']:
    config['model'] = models.choose_model(flags['model'])
    save_config(config)
model_name = config['model']

prompt_name, prompt = command_handler.prompt(commands['prompt'])
if prompt:
    messages.append({'role': 'user', 'content': prompt})
    messages.append({'role': 'assistant', 'content': 'Understood'})

file_content = command_handler.file(commands['file'])
if file_content:
    rprint(f'[yellow]File content loaded: {commands["file"]}[/]')
    messages.append({'role': 'user', 'content': file_content})
    messages.append({'role': 'assistant', 'content': 'How can I assist you?'})

if not commands['query'] and not flags['interactive']:
    while not commands['query']:
        commands['query'] = initial_message()

if commands['query']:
    messages.append({'role': 'user', 'content': commands['query']})

if flags['interactive']:
    if flags['verbose']:
        terminal.print_verbose(model_name, messages, flags,
                              commands, parameters, prompt_name, None)
    interactive_session(model_name, messages, flags, commands, parameters)

if flags['debug']:
    rprint(f'messages: {messages}')

terminal.print_title(model_name, to_stderr=True)

session_data = passive_session(
    model_name, messages, flags, commands, parameters)

finish_reason_check(session_data['finish_reason'])

if flags['verbose']:
    terminal.print_title(model_name)
    terminal.print_verbose(model_name, messages, flags, commands,
                          parameters, prompt_name, session_data['tokens'])

send_to_clipboard(session_data['content'])
if flags['synchronous'] or flags['verbose']:
    print(session_data['content'])
